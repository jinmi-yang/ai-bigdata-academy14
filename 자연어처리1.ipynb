{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#읽은 데이터를 슬래쉬를 기준으로 태그와 함께 나열하는 데이터 전처리 과정 셀\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "def sent_processing(lines):\n",
    "\n",
    "    if isinstance(lines, list):\n",
    "        lines = [line.strip().split(\" \") for line in lines]\n",
    "\n",
    "        corpus = []\n",
    "        for line in lines:\n",
    "            sent = []\n",
    "            for word in line:\n",
    "                word = tuple(word.rsplit(\"/\", 1))\n",
    "                sent.append(word)\n",
    "            corpus.append(sent)\n",
    "\n",
    "        return corpus\n",
    "\n",
    "    elif isinstance(lines, str):\n",
    "        line = []\n",
    "        for word in lines.strip().split(\" \"):\n",
    "            word = tuple(word.rsplit(\"/\", 1))\n",
    "            line.append(word)\n",
    "        return line\n",
    "\n",
    "    else:\n",
    "        print(\"wrong type of input sentence\")\n",
    "        exit(1)\n",
    "\n",
    "    \n",
    "with open(\"corpus.txt\", \"r\", encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "corpus = sent_processing(lines) #처리된 데이터를 corpus에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(corpus):\n",
    "\n",
    "    def bigram_count(sent):\n",
    "        poslist = [pos for _, pos in sent] # [NN, VBD, DT, NN]\n",
    "        return [(pos0, pos1) for pos0, pos1 in zip(poslist, poslist[1:])]\n",
    "\n",
    "    pos2words_freq = defaultdict(lambda: defaultdict(int)) # number of (word, tag)\n",
    "    trans_freq = defaultdict(int) # bigram count --> (tag-1, tag)\n",
    "\n",
    "    # sent format: [(word, tag), (word, tag), ...,(word, tag)]\n",
    "    #corpus의 내부에서 반복문을 돈다.\n",
    "    for sent in corpus: # counting\n",
    "        for word, pos in sent: #튜플 하나하나 들어간다. 워드와 태그를 받음\n",
    "            pos2words_freq[pos][word] +=1 \n",
    "#책에서 참고 가능하듯이, {CMC:{아버지:10, 올림핌:15..}..} 처럼 딕셔너리 안에 딕셔너리(이중딕셔너리)로 한 태그에 대한 단어와 그 개수를 나열\n",
    "\n",
    "        for bigram in bigram_count(sent):\n",
    "            trans_freq[bigram] +=1\n",
    "#책에서 참고 가능하듯이, {(CMC, fjb):20, ...}처럼 태그가 연속되는 것이 몇 개인지 체크하는 과정\n",
    "# + 첫번쨰와 마지막 태그는 BOS와 EOS가 태그 중에 없으므로 따로 입력해서 추가해준다.\n",
    "\n",
    "        trans_freq[('BOS', sent[0][1])] += 1 # number of (BOS, tag) bigram\n",
    "        trans_freq[(sent[-1][1], 'EOS')] +=1 # number of (tag, EOS) bigram\n",
    "\n",
    "    ### Practice1: emission prob p(x|y) \n",
    "    # base는 분모 (반복문으로 딕셔너리 안에 접근하여, 아버지를 구하고 싶으면, 아버지 개수 / CMC 개수 형태로 확률을 구한다.\n",
    "    \n",
    "    # base prob: p(y).\n",
    "    base = {pos: sum(words_dic.values()) for pos, words_dic in pos2words_freq.items()}\n",
    "    # P(y) for every y (count for each tag): {'CMC': count(CMC), 'CMP': count(CMP),..}  \n",
    "    \n",
    "    # p(x|y) = p(x, y) / p(y)\n",
    "    pos2words_prob = defaultdict(lambda: defaultdict(float))\n",
    "    for pos, words_dic in pos2words_freq.items():\n",
    "        for word, count in words_dic.items():\n",
    "            pos2words_prob[pos][word] = math.log(count/base[pos])\n",
    "            \n",
    "    # log(p(x, y)/p(y)) for every (x, y)\n",
    "    # Do something..\n",
    "    \n",
    "    ### Practice2: transition prob p(y_t|y_(t-1))\n",
    "    # base prob: p(y_(t-1))\n",
    "    # (CMC,fgb)의 순서로 나온 개수 / CMC가 앞에 오는 경우의 전체합 으로 확률을 구한다.\n",
    "    base = defaultdict(int)\n",
    "    for (pos1, pos2), count in trans_freq.items():\n",
    "        base[pos1] += count\n",
    "    # Do something to make {'CMC': count('CMC'), 'fjb': count('fjb'), ..}\n",
    "\n",
    "    # p(y_t|y_(t-1)) = p(y_t, y_(t-1)) / p(y_(t-1))\n",
    "    trans_prob = {(pos1, pos2) : math.log(count/ base[pos1]) for (pos1,pos2), count in trans_freq.items()}\n",
    "    # Do something -> p(y_t, y_t-1) / p(y_t) \n",
    "    \n",
    "    return pos2words_prob, trans_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "명사 라면의 확률: -9.427948631791715\n",
      "연결어미 라면의 확률: -5.6937321388027\n"
     ]
    }
   ],
   "source": [
    "pos2words, trans = train(corpus)\n",
    "\n",
    "print('명사 라면의 확률:', pos2words['CMC']['라면']) # 명사 '라면'의 확률 (신라면, 진라면 등.)\n",
    "print('연결어미 라면의 확률:', pos2words['fmoc']['라면']) # 연결어미 '라면'의 확률 (~ 이라면)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM_tagger(object):\n",
    "    def __init__(self, pos2words, trans):\n",
    "        self.pos2words = pos2words\n",
    "        self.trans = trans\n",
    "        self.unk = -15 #unknown word (모르는 단어) 학습했던 패턴이나 데이터에 등장하는 것 외에 등장하는 것\n",
    "        self.eos ='EOS'\n",
    "        self.bos ='BOS'\n",
    "\n",
    "    def sent_log_prob(self, sent):\n",
    "        # emission prob. (단어에 대한 태그 확률)\n",
    "        log_prob = sum(\n",
    "            (self.pos2words.get(tag, {}).get(word, self.unk) for word, tag in sent)\n",
    "            # do someting..\n",
    "         ) # get emission prob. for each (w, t), otherwise unk value\n",
    "\n",
    "        # transition prob.\n",
    "        bigrams = [(t0, t1) for (_, t0), (_, t1) in zip(sent, sent[1:])] # every bigram in sentence\n",
    "        #하나씩 엇나가면서 묶은 튜플을 리스트로 만든 것\n",
    "        log_prob+= sum(\n",
    "            (self.trans.get(b, self.unk) for b in bigrams)\n",
    "            # do something..\n",
    "        )\n",
    "        \n",
    "        #get함수는 get(a)하면 key가 a인 것에 대한 value를 반환한다. 이 때, get(a,b)하면 key가 a인 value를 반환하되, 그 값이 없으면 b를 반환\n",
    "        # bos\n",
    "        log_prob += self.trans.get((self.bos, sent[0][1]), self.unk) # get BOS prob for the first (w, t)\n",
    "\n",
    "        # eos\n",
    "        log_prob += self.trans.get((sent[-1][1], self.eos), self.unk) # get EOS prob for the last (w, t)\n",
    "        \n",
    "        # length norm.\n",
    "        log_prob /= len(sent)\n",
    "\n",
    "        return log_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "감기/CMC 는/fjb 줄이/YBD 다/fmof ./g: -5.489636\n",
      "감기/fmotg 는/fjb 줄/CMC 이다/fjj ./g: -14.037157\n"
     ]
    }
   ],
   "source": [
    "tagger = HMM_tagger(pos2words, trans)\n",
    "test_sent1= \"감기/CMC 는/fjb 줄이/YBD 다/fmof ./g\"\n",
    "test_sent2= \"감기/fmotg 는/fjb 줄/CMC 이다/fjj ./g\"\n",
    "print(\"%s: %f\" % (test_sent1, tagger.sent_log_prob(sent_processing(test_sent1))))\n",
    "print(\"%s: %f\" % (test_sent2, tagger.sent_log_prob(sent_processing(test_sent2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIBD",
   "language": "python",
   "name": "aibd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
